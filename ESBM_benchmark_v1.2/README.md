# ESBM Benchmark v1.2
https://w3id.org/esbm

Last update: 2019-12-08

License: [ODC Attribution License (ODC-By)](https://opendatacommons.org/licenses/by/1-0/index.html)

ESBM (short for Entity Summarization BenchMark) is a benchmark for evaluating algorithms for entity summarization, aka entity summarizers.


# Download

* ESBM_benchmark: data of ESBM;
* Evaluator (jar, src): executable package and example code of the evaluator;
* summ_example: example of output files generated by an entity summarizer to be evaluated;
* runs: output files generated by selected entity summarizers.

# Data

The ESBM benchmark consists of 175 entities (see elist.txt) selected from [DBpedia](http://wiki.dbpedia.org/dbpedia-dataset-version-2015-10) and [LinkedMDB](http://www.cs.toronto.edu/~oktie/linkedmdb/linkedmdb-latest-dump.zip). For each entity, we provide its original description to be summarized and its gold-standard summaries created by crowdsourcing, all available as N-Triples documents.

* <code>desc</code>: entity description to be summarized;
* <code>top5</code>: six gold-standard summaries independently created by different people under <strong>k=5</strong> (i.e., 5 triples in each summary);
* <code>top10</code>: six gold-standard summaries independently created by different people under <strong>k=10</strong> (i.e., 10 triples in each summary).

We split our data into 5 equally sized subsets for performing 5-fold cross-validation.

* <code>S</code>: subsets
* <code>Fold</code>: folds

<pre>
Fold	train.txt	valid.txt	test.txt
Fold0	S0, S1, S2	S3		S4
Fold1	S1, S2, S3	S4		S0
Fold2	S2, S3, S4	S0		S1
Fold3	S3, S4, S0	S1		S2
Fold4	S4, S0, S1	S2		S3
</pre>

The directory structure of these files is as follows.

<pre>
|--ESBM_benchmark
	|-- readme.txt
	|-- dbpedia_data
		|-- 1
			|-- 1_desc.nt
			|-- 1_gold_top5_0.nt
			|-- 1_gold_top5_1.nt
			|-- ...
			|-- 1_gold_top5_5.nt
			|-- 1_gold_top10_0.nt
			|-- 1_gold_top10_1.nt
			|-- ...
			|-- 1_gold_top10_0.nt
		|-- 2
		|-- ...
		|-- 100	
		|-- 141	
		|-- ...
		|-- 165	
	|-- dbpedia_split
		|-- Fold0
			|-- train.txt
			|-- valid.txt
			|-- test.txt			
		|-- Fold1
		|-- ...
		|-- Fold4
		|-- S0.txt
		|-- ...
		|-- S4.txt
  	|-- lmdb_data
		|-- 101
			|-- 101_desc.nt
			|-- 101_gold_top5_0.nt
			|-- ...
		|-- 102
		|-- ...
		|-- 140
		|-- 166
		|-- ...
		|-- 175
	|-- dbpedia_split
		|-- Fold0
			|-- train.txt
			|-- valid.txt
			|-- test.txt			
		|-- Fold1
		|-- ...
		|-- Fold4
		|-- S0.txt
		|-- ...
		|-- S4.txt
</pre>

# Evaluation

An evaluator written in Java is provided for evaluating your own entity summarizer based on the ESBM benchmark.

## Required Output Format

Summaries generated by your entity summarizer to be evaluated should be outputted also as N-Triples documents (see OutputExample.java in src). For each entity, provide the following output files generated by your entity summarizer.

* <code>top5</code>: summary generated by your entity summarizer under <strong>k=5</strong>;
* <code>top10</code>: summary generated by your entity summarizer under <strong>k=10</strong>;
* <code>rank</code>: ranked list of all the triples in the entity description. This file is optional. Provide it only if your entity summarizer is capable of generating a ranking of all the triples, so that our evaluator can report its NDCG score.
The directory structure of these files should be as follows.

<pre>|--summ_example
	|-- dbpedia
		|-- 1
			|-- 1_top5.nt
			|-- 1_top10.nt
			|-- 1_rank.nt
		|-- 2
		|-- ...
		|-- 100	
		|-- 141	
		|-- ...
		|-- 165	
  	|-- lmdb
		|-- 101
			|-- 101_top5.nt
			|-- 101_top10.nt
			|-- 101_rank.nt
		|-- 102
		|-- ...
		|-- 140
		|-- 166
		|-- ...
		|-- 175
</pre>

An example of output files is given in <code>summ_example</code>.

## Run the Evaluator

Unzip the benchmark data before running the evaluator.

The evaluator receives two arguments:

Path of the benchmark data, e.g. <code>/home/user/eval/ESBM_benchmark/</code>
Path of the output files generated by your entity summarizer, e.g. <code>/home/user/eval/summ_example/</code>
Run the evaluator (jar) using the following command (Java 8 is required):

<pre>$ java -jar esummeval_v1.2.jar /home/user/eval/ESBM_benchmark_v1.2/ /home/user/eval/summ_example/
</pre>

Output of the evaluator will look like:


<pre>******************************************
Evaluating with settings:
 benchmark directory: /home/user/eval/ESBM_benchmark/
 summarizer output directory: /home/user/eval/summ_example/

=================
Dataset: dbpedia
Results(dbpedia@top5):	F-measure=0.24240000000000003, NDCG=0.6986843638071224
Results(dbpedia@top10):	F-measure=0.4554666666666666, NDCG=0.7947487531754833
=================
Dataset: lmdb
Results(lmdb@top5):	F-measure=0.20333333333333337, NDCG=0.5858502776281002
Results(lmdb@top10):	F-measure=0.258, NDCG=0.6895312848004972
=================
For all 175 entities: 
Results(all@top5):	F-measure=0.23123809523809524, NDCG=0.666446053470259
Results(all@top10):	F-measure=0.39904761904761904, NDCG=0.7646866193540586
</pre>
Results for <code>dbpedia</code>, <code>lmdb</code> and <code>all</code> are averaged over 125, 50, and 175 entities, respectively, even if your entity summarizer does not provide summaries for all the entities.

## Submit Your Results

Evaluation results for several selected entity summarizers are presented in Table 1 and Table 2. Their output files are also available (runs).

You are encouraged to submit the results of your entity summarizer by contacting us. We will add your results to the following tables. Your submission should contain:

* <code>Output files</code>: summaries generated by your entity summarizer;
* <code>Evaluation results</code>: evaluation results outputted by our evaluator;
* <code>Notes</code>: brief description of your entity summarizer (e.g., name of the summarizer, citation information, parameter settings).

<strong>Table 1. F-measure of selected entity summarizers under their best parameter settings</strong>

<table class="tablesorter" id="tb_fmeasure">
<thead>
<tr>
<th rowspan="2" data-sorter="false" class="header"></th>
<th colspan="2" class="nosort header">DBpedia</th>
<th colspan="2" class="nosort header">LinkedMDB</th>
<th colspan="2" class="nosort header">All</th>
</tr>
<tr>
<th id="dbp1" class="header">k=5</th>
<th id="dbp2" class="header">k=10</th>
<th id="lmdb1" class="header">k=5</th>
<th id="lmdb1" class="header">k=10</th>
<th id="all1" class="header">k=5</th>
<th id="all1" class="header">k=10</th>
</tr>
</thead>
<tbody><tr>
<td>RELIN [1]</td>
<td name="td1">0.242<br><span></span></td>
<td name="td2">0.455<br><span></span></td>
<td name="td3">0.203<br><span></span></td>
<td name="td4">0.258<br><span></span></td>
<td name="td5">0.231<br><span></span></td>
<td name="td6">0.399<br><span></span></td>
</tr><tr>
<td>DIVERSUM [2]</td>
<td name="td1">0.249</td>
<td name="td2">0.507</td>
<td name="td3">0.207</td>
<td name="td4">0.358</td>
<td name="td5">0.237</td>
<td name="td6">0.464</td>
</tr>
<tr>
<td>FACES [3]</td>
<td name="td1">0.270</td>
<td name="td2">0.428</td>
<td name="td3">0.169</td>
<td name="td4">0.263</td>
<td name="td5">0.241</td>
<td name="td6">0.381</td>
</tr>
<tr>
<td>FACES-E [4]</td>
<td name="td1">0.280</td>
<td name="td2">0.488</td>
<td name="td3">0.313</td>
<td name="td4">0.393</td>
<td name="td5">0.289</td>
<td name="td6">0.461</td>
</tr>
<tr>
<td>CD [5]<br></td>
<td name="td1">0.283</td>
<td name="td2">0.513</td>
<td name="td3">0.217<br></td>
<td name="td4">0.331<br></td>
<td name="td5">0.264<br></td>
<td name="td6">0.461<br></td>
</tr>
<tr>
<td>LinkSUM [6]</td>
<td name="td1">0.287<br></td>
<td name="td2">0.486<br></td>
<td name="td3">0.140<br></td>
<td name="td4">0.279<br></td>
<td name="td5">0.245<br></td>
<td name="td6">0.427<br></td>
</tr>
<tr>
<td>BAFREC [7]</td>
<td name="td1">0.335</td>
<td name="td2">0.503</td>
<td name="td3">0.360</td>
<td name="td4">0.402</td>
<td name="td5">0.342</td>
<td name="td6">0.474</td>
</tr>
<tr>
<td>KAFCA [8]</td>
<td name="td1">0.314<br></td>
<td name="td2">0.509<br></td>
<td name="td3">0.244<br></td>
<td name="td4">0.397<br></td>
<td name="td5">0.294<br></td>
<td name="td6">0.477<br></td>
</tr>
<tr>
<td>MPSUM [9]</td>
<td name="td1">0.314</td>
<td name="td2">0.512</td>
<td name="td3">0.272</td>
<td name="td4">0.423</td>
<td name="td5">0.302</td>
<td name="td6">0.486</td>
</tr>
</tbody></table>

<strong>Table 2. NDCG of selected entity summarizers under their best parameter settings </strong>

<table class="tablesorter" id="tb_map">
<thead>
<tr>
<th rowspan="2" data-sorter="false" class="header"></th>
<th colspan="2" class="nosort header">DBpedia</th>
<th colspan="2" class="nosort header">LinkedMDB</th>
<th colspan="2" class="nosort header">All</th>
</tr>
<tr>
<th id="dbp1" class="header">k=5</th>
<th id="dbp2" class="header">k=10</th>
<th id="lmdb1" class="header">k=5</th>
<th id="lmdb1" class="header">k=10</th>
<th id="all1" class="header">k=5</th>
<th id="all1" class="header">k=10</th>
</tr>
</thead>
<tbody><tr>
<td>RELIN [1]</td>
<td name="td1">0.699<br><span></span></td>
<td name="td2">0.795<br><span></span></td>
<td name="td3">0.586<br><span></span></td>
<td name="td4">0.690<br><span></span></td>
<td name="td5">0.666<br><span></span></td>
<td name="td6">0.765<br><span></span></td>
</tr><tr>
<td>DIVERSUM [2]</td>
<td name="td1">0.646</td>
<td name="td2">0.757</td>
<td name="td3">0.589</td>
<td name="td4">0.714</td>
<td name="td5">0.630</td>
<td name="td6">0.745</td>
</tr>
<tr>
<td>FACES [3]</td>
<td name="td1">0.523</td>
<td name="td2">0.711</td>
<td name="td3">0.390</td>
<td name="td4">0.565</td>
<td name="td5">0.485</td>
<td name="td6">0.669</td>
</tr>
<tr>
<td>FACES-E [4]</td>
<td name="td1">0.735</td>
<td name="td2">0.836</td>
<td name="td3">0.674</td>
<td name="td4">0.765</td>
<td name="td5">0.718</td>
<td name="td6">0.816</td>
</tr>
<tr>
<td>CD [5]<br></td>
<td name="td1">-</td>
<td name="td2">-</td>
<td name="td3">-</td>
<td name="td4">-</td>
<td name="td5">-</td>
<td name="td6">-</td>
</tr>
<tr>
<td>LinkSUM [6]</td>
<td name="td1">0.505<br><span></span></td>
<td name="td2">0.699<br><span></span></td>
<td name="td3">0.371<br><span></span></td>
<td name="td4">0.574<br><span></span></td>
<td name="td5">0.467<br><span></span></td>
<td name="td6">0.663<br><span></span></td>
</tr>
<tr>
<td>BAFREC [7]</td>
<td name="td1">0.752</td>
<td name="td2">0.832</td>
<td name="td3">0.773</td>
<td name="td4">0.827</td>
<td name="td5">0.758</td>
<td name="td6">0.830</td>
</tr>
<tr>
<td>KAFCA [8]</td>
<td name="td1">0.737<br></td>
<td name="td2">0.851</td>
<td name="td3">0.640<br></td>
<td name="td4">0.754<br></td>
<td name="td5">0.709<br></td>
<td name="td6">0.823<br></td>
</tr>
<tr>
<td>MPSUM [9]</td>
<td name="td1">0.745</td>
<td name="td2">0.831</td>
<td name="td3">0.694</td>
<td name="td4">0.787</td>
<td name="td5">0.730</td>
<td name="td6">0.819</td>
</tr>
</tbody></table>

## Additional Results
 
<strong>Table 3. F-measure (max over different ground-truth summaries) </strong>
<table class="tablesorter" id="tb_fmeasure2">
<thead>
<tr>
<th rowspan="2" data-sorter="false" class="header"></th>
<th colspan="2" class="nosort header">DBpedia</th>
<th colspan="2" class="nosort header">LinkedMDB</th>
<th colspan="2" class="nosort header">All</th>
</tr>
<tr>
<th id="dbp1" class="header">k=5</th>
<th id="dbp2" class="header">k=10</th>
<th id="lmdb1" class="header">k=5</th>
<th id="lmdb1" class="header">k=10</th>
<th id="all1" class="header">k=5</th>
<th id="all1" class="header">k=10</th>
</tr>
</thead>
<tbody><tr>
<td>RELIN [1]</td>
<td name="td1">0.405<br><span></span></td>
<td name="td2">0.591<br><span></span></td>
<td name="td3">0.400<br><span></span></td>
<td name="td4">0.448<br><span></span></td>
<td name="td5">0.403<br><span></span></td>
<td name="td6">0.550<br><span></span></td>
</tr><tr>
<td>DIVERSUM [2]</td>
<td name="td1">0.416</td>
<td name="td2">0.647</td>
<td name="td3">0.352</td>
<td name="td4">0.514</td>
<td name="td5">0.398</td>
<td name="td6">0.609</td>
</tr>
<tr>
<td>FACES [3]</td>
<td name="td1">0.458</td>
<td name="td2">0.556</td>
<td name="td3">0.313</td>
<td name="td4">0.372</td>
<td name="td5">0.417</td>
<td name="td6">0.504</td>
</tr>
<tr>
<td>FACES-E [4]</td>
<td name="td1">0.458</td>
<td name="td2">0.615</td>
<td name="td3">0.476</td>
<td name="td4">0.548</td>
<td name="td5">0.463</td>
<td name="td6">0.596</td>
</tr>
<tr>
<td>CD [5]<br></td>
<td name="td1">0.475</td>
<td name="td2">0.647</td>
<td name="td3">0.420<br></td>
<td name="td4">0.484<br></td>
<td name="td5">0.459<br></td>
<td name="td6">0.601<br></td>
</tr>
<tr>
<td>LinkSUM [6]</td>
<td name="td1">0.495<br></td>
<td name="td2">0.637<br></td>
<td name="td3">0.260<br></td>
<td name="td4">0.416<br></td>
<td name="td5">0.428<br></td>
<td name="td6">0.574<br></td>
</tr>
<tr>
<td>BAFREC [7]</td>
<td name="td1">0.554</td>
<td name="td2">0.641</td>
<td name="td3">0.552</td>
<td name="td4">0.572</td>
<td name="td5">0.553</td>
<td name="td6">0.621</td>
</tr>
<tr>
<td>KAFCA [8]</td>
<td name="td1">0.314<br></td>
<td name="td2">0.509<br></td>
<td name="td3">0.244<br></td>
<td name="td4">0.397<br></td>
<td name="td5">0.294<br></td>
<td name="td6">0.477<br></td>
</tr>
<tr>
<td>MPSUM [9]</td>
<td name="td1">0.501</td>
<td name="td2">0.646</td>
<td name="td3">0.472</td>
<td name="td4">0.568</td>
<td name="td5">0.493</td>
<td name="td6">0.624</td>
</tr>
</tbody></table>


# References

<p>
[1] Gong Cheng, Thanh Tran, Yuzhong Qu: RELIN: Relatedness and Informativeness-Based Centrality for Entity Summarization. International Semantic Web Conference (1) 2011: 114-129. <br>
[2] Marcin Sydow, Mariusz Pikula, Ralf Schenkel: The notion of diversity in graphical entity summarisation on semantic knowledge graphs. J. Intell. Inf. Syst. 41(2): 109-149 (2013).<br>
[3] Kalpa Gunaratna, Krishnaprasad Thirunarayan, Amit P. Sheth: FACES: Diversity-Aware Entity Summarization Using Incremental Hierarchical Conceptual Clustering. AAAI 2015: 116-122.<br>
[4] Kalpa Gunaratna, Krishnaprasad Thirunarayan, Amit P. Sheth, Gong Cheng: Gleaning Types for Literals in RDF Triples with Application to Entity Summarization. ESWC 2016: 85-100.<br>
[5] Danyun Xu, Liang Zheng, Yuzhong Qu: CD at ENSEC 2016: Generating Characteristic and Diverse Entity Summaries. SumPre@ESWC 2016.<br>
[6] Andreas Thalhammer, Nelia Lasierra, Achim Rettinger: LinkSUM: Using Link Analysis to Summarize Entity Data. ICWE 2016: 244-261.<br>
[7] Hermann Kroll, Denis Nagel and Wolf-Tilo Balke: BAFREC: Balancing Frequency and Rarity for Entity Characterization in Linked Open Data. EYRE 2018.<br>
[8] Eun-Kyung Kim and Key-Sun Choi: Entity Summarization Based on Formal Concept Analysis. EYRE 2018.<br>
[9] Dongjun Wei, Shiyuan Gao, Yaxin Liu, Zhibing Liu and Longtao Huang: MPSUM: Entity Summarization with Predicate-based Matching. EYRE 2018.
</p>

# Contact
If you have any questions or suggestions, please feel free to contact [Qingxia Liu](http://ws.nju.edu.cn/people/qxliu) and [Gong Cheng](http://ws.nju.edu.cn/~gcheng). This work is also credited to Kalpa Gunaratna.

# Citation
If you use this benchmark, please cite the following paper (Best Resource Track Paper Nominee of [ESWC 2020](https://2020.eswc-conferences.org), Video of this paper can be found [here](https://youtu.be/arLGlplC8Kk)):

```
@inproceedings{esbm,
  author    = {Qingxia Liu and
                Gong Cheng and
                Kalpa Gunaratna and
                Yuzhong Qu},
  title     = {ESBM: An Entity Summarization Benchmark},
  booktitle = {ESWC},
  year      = {2020}
}
```